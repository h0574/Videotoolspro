#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import http.server
import socketserver
import json
import subprocess
import os
import threading
import time
import re
import shlex
import sys
import queue
from math import ceil

# --- B∆Ø·ªöC 1: C√ÄI ƒê·∫∂T TH∆Ø VI·ªÜN (N·∫æU CH∆ØA C√ì) ---
try:
    import google.generativeai as genai
except ImportError:
    print("‚ùå Th∆∞ vi·ªán google-generativeai ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t.")
    print("üëâ M·ªü Terminal ho·∫∑c Command Prompt, g√µ l·ªánh: pip3 install google-generativeai")
    sys.exit()

# --- B∆Ø·ªöC 2: C·∫§U H√åNH API KEY C·ª¶A M√ÄY ---
API_KEYS = [
    "AIzaSyACi9OiKAOcaZdJaRvlz_lMFBQpzgHhepI",
    "AIzaSyA2jHB9dhzbPhbMbylIQkdgm63UhgLAgvU", 
]

# --- CONFIGURATION ---
DEFAULT_DOWNLOAD_PATH = os.path.expanduser("~/Downloads/dlp")
PORT = 8000

# ==============================================================================
# PH·∫¶N LOGIC D·ªäCH THU·∫¨T & S√ÅNG T·∫†O N·ªòI DUNG (T·ª™ SCRIPT C·ª¶A M√ÄY)
# ==============================================================================

def parse_srt(srt_content):
    if srt_content.startswith('\ufeff'): srt_content = srt_content[1:]
    srt_content = srt_content.replace('\r\n', '\n').strip()
    pattern = re.compile(r'(\d+)\n(\d{2}:\d{2}:\d{2}[,.]\d{1,3}\s*-->\s*\d{2}:\d{2}:\d{2}[,.]\d{1,3})\n([\s\S]+?)(?=\n\n|\Z)', re.MULTILINE)
    return pattern.findall(srt_content)

def parse_capcut_json_to_srt(json_content):
    try:
        data = json.loads(json_content)
        if "materials" not in data or "texts" not in data["materials"]:
             raise ValueError("Kh√¥ng t√¨m th·∫•y key 'materials' ho·∫∑c 'texts' trong file JSON.")

        texts = data["materials"]["texts"]
        srt_lines = []
        
        sorted_texts = sorted(texts, key=lambda x: x.get('start_time', 0))

        for index, text_info in enumerate(sorted_texts):
            content = text_info.get("content", "").strip()
            if not content:
                continue

            start_us = text_info.get("start_time", 0)
            end_us = text_info.get("end_time", 0)

            start_s = start_us / 1_000_000
            end_s = end_us / 1_000_000

            start_time = time.strftime('%H:%M:%S', time.gmtime(start_s)) + f",{int((start_s % 1) * 1000):03d}"
            end_time = time.strftime('%H:%M:%S', time.gmtime(end_s)) + f",{int((end_s % 1) * 1000):03d}"
            
            srt_lines.append(str(index + 1))
            srt_lines.append(f"{start_time} --> {end_time}")
            srt_lines.append(content)
            srt_lines.append("")

        if not srt_lines:
            raise ValueError("Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu ph·ª• ƒë·ªÅ n√†o trong file CapCut JSON.")
            
        return "\n".join(srt_lines)
    except json.JSONDecodeError:
        raise ValueError("File kh√¥ng ph·∫£i l√† ƒë·ªãnh d·∫°ng JSON h·ª£p l·ªá.")
    except Exception as e:
        print(f"L·ªói khi x·ª≠ l√Ω file CapCut JSON: {e}")
        raise

def count_words(text):
    chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', text))
    vietnamese_words = len(re.findall(r'[a-zA-Z√Ä-·ªπ]+', text))
    return chinese_chars + vietnamese_words

def get_content_summary(translated_subtitles):
    total_lines = len(translated_subtitles)
    start_section = translated_subtitles[:int(total_lines * 0.3)]
    start_text = " ".join([sub[2] for sub in start_section])
    middle_start = int(total_lines * 0.35)
    middle_end = int(total_lines * 0.65)
    middle_section = translated_subtitles[middle_start:middle_end]
    middle_text = " ".join([sub[2] for sub in middle_section])
    end_start = int(total_lines * 0.7)
    end_section = translated_subtitles[end_start:]
    end_text = " ".join([sub[2] for sub in end_section])
    return {"start": start_text[:500], "middle": middle_text[:500], "end": end_text[:500]}

def generate_caption_and_thumbnail(content_summary):
    caption_prompt = f"""
M√†y l√† m·ªôt Copywriter chuy√™n nghi·ªáp, c√≥ kh·∫£ nƒÉng vi·∫øt nhi·ªÅu style caption kh√°c nhau cho video review phim tr√™n YouTube/TikTok.
D·ª±a v√†o n·ªôi dung phim ƒë∆∞·ª£c t√≥m t·∫Øt b√™n d∆∞·ªõi, h√£y t·∫°o cho tao **3 L·ª∞A CH·ªåN CAPTION** v·ªõi 3 phong c√°ch ri√™ng bi·ªát.
**N·ªòI DUNG PHIM:**
- Ph·∫ßn ƒë·∫ßu: {content_summary['start']}
- Ph·∫ßn gi·ªØa: {content_summary['middle']}
- Ph·∫ßn cu·ªëi: {content_summary['end']}
**Y√äU C·∫¶U CHUNG:**
- M·ªói caption ph·∫£i c√≥ hashtag v√† emoji ph√π h·ª£p.
- Ng√¥n ng·ªØ t·ª± nhi√™n, h·∫•p d·∫´n, ƒë√∫ng ch·∫•t GenZ.
**3 PHONG C√ÅCH B·∫ÆT BU·ªòC M√ÄY PH·∫¢I VI·∫æT:**
1.  **CAPTION T√í M√í:** T·∫≠p trung ƒë·∫∑t c√¢u h·ªèi, t·∫°o ra m·ªôt b√≠ ·∫©n l·ªõn.
2.  **CAPTION GI·∫¨T T√çT:** D√πng t·ª´ ng·ªØ m·∫°nh, g√¢y s·ªëc, ƒë√¥i khi h∆°i "l∆∞∆°n l·∫πo" ƒë·ªÉ c√¢u view.
3.  **CAPTION H√ÄI H∆Ø·ªöC / C√Ä KH·ªäA:** Nh√¨n v√†o m·ªôt g√≥c ƒë·ªô h√†i h∆∞·ªõc, v√¥ l√Ω ho·∫∑c "t·∫•u h√†i" c·ªßa phim.
**FORMAT TR·∫¢ V·ªÄ (C·ª∞C K·ª≤ QUAN TR·ªåNG, PH·∫¢I THEO ƒê√öNG 100%):**
=== CAPTION T√í M√í ===
[N·ªôi dung caption 1]
#hashtag #hashtag

=== CAPTION GI·∫¨T T√çT ===
[N·ªôi dung caption 2]
#hashtag #hashtag

=== CAPTION H√ÄI H∆Ø·ªöC / C√Ä KH·ªäA ===
[N·ªôi dung caption 3]
#hashtag #hashtag
"""
    thumbnail_prompt = f"""
M√†y l√† designer thumbnail YouTube/TikTok chuy√™n nghi·ªáp, bi·∫øt c√°ch t·∫°o text h√∫t m·∫Øt.
D·ª±a v√†o n·ªôi dung phim sau, t·∫°o cho tao text ng·∫Øn g·ªçn ƒë·ªÉ l√†m thumbnail:
**N·ªòI DUNG PHIM:**
- Ph·∫ßn ƒë·∫ßu: {content_summary['start']}
- Ph·∫ßn gi·ªØa: {content_summary['middle']}
- Ph·∫ßn cu·ªëi: {content_summary['end']}
**Y√äU C·∫¶U TEXT THUMBNAIL:**
1. ƒê·ªò D√ÄI: T·ªëi ƒëa 5 T·ª™ (words), tuy·ªát ƒë·ªëi kh√¥ng vi·∫øt d√†i h∆°n.
2. Ph·∫£i shock, g√¢y t√≤ m√≤.
3. D√πng t·ª´ m·∫°nh, c√≥ t√°c ƒë·ªông.
**FORMAT:**
[TEXT D√íNG 1]
[TEXT D√íNG 2] (n·∫øu c·∫ßn)
Ch·ªâ tr·∫£ text th√¥i, kh√¥ng gi·∫£i th√≠ch g√¨ th√™m.
"""
    try:
        genai.configure(api_key=API_KEYS[0])
        model = genai.GenerativeModel('gemini-1.5-flash')
        caption_response = model.generate_content(caption_prompt, request_options={'timeout': 180})
        caption_text = caption_response.text.strip()
        thumbnail_response = model.generate_content(thumbnail_prompt, request_options={'timeout': 120})
        thumbnail_text = thumbnail_response.text.strip()
        return caption_text, thumbnail_text
    except Exception as e:
        return f"T·∫°o caption l·ªói: {e}", "PHIM HAY"

def get_translation_prompt(is_intro=False):
    if is_intro:
        return """
M√†y l√† Bi√™n K·ªãch M·∫∑n M√≤i c·ªßa k√™nh ƒê·∫ßy B·ª•ng Review, m·ªôt b·∫≠c th·∫ßy gi·∫≠t t√≠t chuy√™n vi·∫øt k·ªãch b·∫£n intro. Nhi·ªám v·ª• c·ªßa m√†y l√† bi·∫øn m·ªôt ƒëo·∫°n k·ªãch b·∫£n g·ªëc nh√†m ch√°n th√†nh m·ªôt c√°i intro 30 gi√¢y c√≥ c√°i hook B√âN NH∆Ø DAO C·∫†O, khi·∫øn ng∆∞·ªùi xem ph·∫£i d·ª´ng l·∫°i ngay l·∫≠p t·ª©c.
‚ö†Ô∏è LU·∫¨T V√ÄNG PH·∫¢I THEO:
1.  **D·ªãch Tho√°t √ù & S√°ng T·∫°o:** B·ªãa th√™m th·∫Øt tho·∫£i m√°i ƒë·ªÉ t·∫°o s·ª± h√†i h∆∞·ªõc, b·∫•t ng·ªù.
2.  **T·∫†O HOOK C·ª∞C M·∫†NH:** V√†i c√¢u ƒë·∫ßu ti√™n ph·∫£i ƒë·∫∑t ra m·ªôt v·∫•n ƒë·ªÅ g√¢y s·ªëc, m·ªôt c√¢u h·ªèi l·ªõn, ho·∫∑c m·ªôt l·ªùi c√† kh·ªãa th√¥ng minh.
3.  **C√ÄI C·∫ÆM TH∆Ø∆†NG HI·ªÜU:** Trong kho·∫£ng 50 d√≤ng ƒë·∫ßu, ph·∫£i kh√©o l√©o nh√©t t√™n k√™nh "**ƒê·∫ßy B·ª•ng Review**" v√†o m·ªôt c√°ch t·ª± nhi√™n. C·∫•m gi·∫£ tr√¢n.
4.  **SI√äU LU·∫¨T V·ªÄ ƒê·ªò D√ÄI (C·∫§M C√ÉI):** C√¢u d·ªãch ti·∫øng Vi·ªát PH·∫¢I c√≥ s·ªë t·ª´ √çT H∆†N ho·∫∑c B·∫∞NG c√¢u g·ªëc.
5.  **X∆∞ng H√¥ Th√¢n Thi·ªán:** D√πng "tao - m√†y", "tui - m·∫•y b√†", "anh em m√¨nh".
6.  **Gi·ªØ Format SRT:** Gi·ªØ nguy√™n c·∫•u tr√∫c [S·ªë] - [Timestamp] - [C√¢u d·ªãch 1 d√≤ng].
"""
    else:
        return """
M√†y l√† m·ªôt Bi√™n K·ªãch Ch√≠nh c√≥ duy√™n, chuy√™n vi·∫øt l·ªùi tho·∫°i cho video YouTube c·ªßa k√™nh ƒê·∫ßy B·ª•ng Review.
‚ö†Ô∏è LU·∫¨T V√ÄNG PH·∫¢I THEO:
1.  **X√ÇY D·ª∞NG C√Å T√çNH:** T·∫°o ra m·ªôt "c√° t√≠nh" nh·∫•t qu√°n cho ng∆∞·ªùi d·ªãch/l·ªìng ti·∫øng (l·∫°c quan t·∫øu, '√¥ng c·ª• non', b·∫°n th√¢n nhi·ªÅu chuy·ªán...).
2.  **K·ªÉ Chuy·ªán C√≥ Nh·ªãp ƒêi·ªáu:** Ph·∫£i bi·∫øt l√∫c n√†o c·∫ßn t·∫•u h√†i, l√∫c n√†o c·∫ßn s√¢u l·∫Øng ƒë·ªÉ ƒë·∫©y c·∫£m x√∫c.
3.  **SI√äU LU·∫¨T V·ªÄ ƒê·ªò D√ÄI (C·∫§M C√ÉI):** C√¢u d·ªãch ti·∫øng Vi·ªát PH·∫¢I c√≥ s·ªë t·ª´ √çT H∆†N ho·∫∑c B·∫∞NG c√¢u g·ªëc.
4.  **B√¨nh Lu·∫≠n Duy√™n D√°ng:** Th·ªânh tho·∫£ng ch√®n th√™m nh·ªØng c√¢u b√¨nh lu·∫≠n ng·∫Øn g·ªçn, h√†i h∆∞·ªõc.
5.  **Gi·ªØ Format SRT:** Gi·ªØ nguy√™n c·∫•u tr√∫c [S·ªë] - [Timestamp] - [C√¢u d·ªãch 1 d√≤ng].
"""

def translate_text(model_instance, text_to_translate, is_batch=False, num_items=1, is_intro=False, previous_context=None):
    if is_batch:
        indexed_texts = [f"[{i+1}] {text.replace(chr(10), ' ').strip()} (S·ªë t·ª´ g·ªëc: {count_words(text)})" for i, text in enumerate(text_to_translate)]
        joined_text = "\n".join(indexed_texts)
        prompt_body = f"VƒÉn b·∫£n c·∫ßn d·ªãch:\n---\n{joined_text}\n---"
    else:
        processed_text = text_to_translate.replace('\n', ' ').strip()
        word_count = count_words(processed_text)
        prompt_body = f"C√¢u c·∫ßn d·ªãch:\n---\n{processed_text} (S·ªë t·ª´ g·ªëc: {word_count})\n---"
    
    prompt_template = get_translation_prompt(is_intro)
    context_prompt = f"<ngu_canh>\n{previous_context}\n</ngu_canh>\n\n" if previous_context else ""
    full_prompt = f"""{prompt_template}\n\n{context_prompt}**QUY T·∫ÆC ƒê·ªäNH D·∫†NG (B·∫ÆT BU·ªòC):**\n- M√†y PH·∫¢I tr·∫£ l·ªùi b·∫±ng m·ªôt danh s√°ch ƒë∆∞·ª£c ƒë√°nh s·ªë y h·ªát nh∆∞ m√†y ƒë√£ nh·∫≠n (n·∫øu c√≥).\n- V√≠ d·ª•: N·∫øu nh·∫≠n "[1] text1\\n[2] text2", m√†y ph·∫£i tr·∫£ l·ªùi "[1] d·ªãch_c√¢u_1\\n[2] d·ªãch_c√¢u_2".\n- TUY·ªÜT ƒê·ªêI kh√¥ng th√™m b·∫•t k·ª≥ k√Ω t·ª± n√†o kh√°c.\n- Kh√¥ng ƒë∆∞·ª£c ghi s·ªë t·ª´ ho·∫∑c ghi ch√∫ g√¨ th√™m.\n\n{prompt_body}"""
    
    response = model_instance.generate_content(full_prompt, request_options={'timeout': 180})
    if not response.parts: raise ValueError(f"AI t·ª´ ch·ªëi d·ªãch. L√Ω do: {getattr(response.prompt_feedback, 'block_reason', 'Kh√¥ng r√µ')}")
    
    raw_text = response.text.strip()
    
    if is_batch:
        pattern = re.compile(r'\[(\d+)\]\s*(.*)')
        matches = pattern.findall(raw_text)
        
        translated_dict = {}
        for match in matches:
            index = int(match[0])
            text_content = match[1].strip()
            # D·ªçn d·∫πp m·∫°nh tay h∆°n
            cleaned_text = re.sub(r'^\d{1,2}:\d{2}:\d{2}[,.]\d{1,3}\s*-->\s*\d{1,2}:\d{2}:\d{2}[,.]\d{1,3}\s*', '', text_content).strip()
            cleaned_text = re.sub(r'^\d{1,2}:\d{2}:\d{2}\s*', '', cleaned_text).strip()
            cleaned_text = re.sub(r'^\d+\s', '', cleaned_text).strip()
            translated_dict[index] = cleaned_text

        if len(translated_dict) == num_items:
            return [translated_dict.get(i + 1, "") for i in range(num_items)]
        else:
            lines = raw_text.split('\n')
            lines = [re.sub(r'^\[?\d+\]?\.?\s*', '', line).strip() for line in lines if line.strip()]
            if len(lines) == num_items:
                return lines
            raise ValueError(f"AI tr·∫£ v·ªÅ sai s·ªë l∆∞·ª£ng d√≤ng ({len(translated_dict)} vs {num_items}). Raw: {raw_text}")
    else:
        return [raw_text]

def shorten_text_aggressively(model_instance, original_text, long_translation, max_attempts=3):
    original_word_count = count_words(original_text)
    current_translation = long_translation
    for attempt in range(max_attempts):
        current_word_count = count_words(current_translation)
        if current_word_count <= original_word_count: return current_translation
        
        shorten_prompt = f"""R√∫t g·ªçn c√¢u d·ªãch sau cho s·ªë t·ª´ ‚â§ {original_word_count} t·ª´ m√† v·∫´n gi·ªØ √Ω ch√≠nh.
- C√¢u g·ªëc (ti·∫øng Trung): "{original_text}" ({original_word_count} t·ª´)
- C√¢u d·ªãch hi·ªán t·∫°i: "{current_translation}" ({current_word_count} t·ª´)
Ch·ªâ tr·∫£ v·ªÅ c√¢u ƒë√£ r√∫t g·ªçn, kh√¥ng gi·∫£i th√≠ch:"""
        try:
            response = model_instance.generate_content(shorten_prompt, request_options={'timeout': 60})
            if not response.parts: break
            current_translation = response.text.strip()
        except Exception: break
    
    if count_words(current_translation) > original_word_count:
        words = current_translation.split()
        if len(words) > original_word_count: current_translation = ' '.join(words[:original_word_count])
    return current_translation

class ProgressTracker:
    def __init__(self, total_items, task_dict, task_id):
        self.total = total_items; self.count = 0; self.lock = threading.Lock()
        self.task_dict = task_dict; self.task_id = task_id
    def update(self, num_items=1):
        with self.lock:
            self.count += num_items
            percentage = (self.count / self.total) * 100
            self.task_dict[self.task_id]['progress'] = percentage
            self.task_dict[self.task_id]['status_text'] = f"ƒêang d·ªãch... {self.count}/{self.total}"

def translation_worker(thread_id, task_queue, results_dict, lock, progress_tracker):
    key_index = thread_id
    previous_batch_context = None
    while not task_queue.empty():
        try:
            batch_num, batch = task_queue.get_nowait()
            original_texts = [sub[2] for sub in batch]
            translated_texts = None
            is_intro_batch = (batch_num == 1)
            
            model = None
            for attempt in range(2):
                try:
                    api_key_to_use = API_KEYS[key_index % len(API_KEYS)]
                    genai.configure(api_key=api_key_to_use)
                    model = genai.GenerativeModel('gemini-1.5-flash')
                    translated_texts = translate_text(model, original_texts, is_batch=True, num_items=len(original_texts), is_intro=is_intro_batch, previous_context=previous_batch_context)
                    if translated_texts and len(translated_texts) == len(original_texts): break
                    else: raise ValueError("S·ªë l∆∞·ª£ng d√≤ng tr·∫£ v·ªÅ kh√¥ng kh·ªõp.")
                except Exception as e:
                    print(f"L·ªói lu·ªìng #{thread_id}, l√¥ {batch_num}: {e}. ƒê·ªïi key v√† th·ª≠ l·∫°i...")
                    key_index += 1
                    if attempt == 1: translated_texts = None

            previous_batch_context = " ".join(original_texts)
            if translated_texts is None: translated_texts = ["L·ªñI D·ªäCH"] * len(original_texts)

            final_texts = []
            if model:
                for i, translated_line in enumerate(translated_texts):
                    original_line = original_texts[i]
                    if count_words(translated_line) > count_words(original_line):
                        shortened_line = shorten_text_aggressively(model, original_line, translated_line)
                        final_texts.append(shortened_line)
                    else:
                        final_texts.append(translated_line)
            else:
                final_texts = translated_texts

            with lock:
                for j, sub in enumerate(batch):
                    results_dict[int(sub[0])] = (sub[1], final_texts[j])
                progress_tracker.update(len(batch))
            task_queue.task_done()
        except queue.Empty: break
        except Exception as e: print(f"L·ªói kh√¥ng x√°c ƒë·ªãnh trong lu·ªìng #{thread_id}: {e}"); break

# ==============================================================================
# HTTP SERVER LOGIC
# ==============================================================================

class YouTubeDownloaderHandler(http.server.SimpleHTTPRequestHandler):
    download_tasks = {}
    translation_tasks = {}

    def do_GET(self):
        if self.path == '/health':
            self._send_json_response({'status': 'ok'})
            return
        if self.path == '/': self.path = '/index.html'
        return http.server.SimpleHTTPRequestHandler.do_GET(self)

    def do_OPTIONS(self):
        self.send_response(200, "ok")
        self.send_header('Access-Control-Allow-Origin', '*')
        self.send_header('Access-Control-Allow-Methods', 'POST, GET, OPTIONS')
        self.send_header("Access-Control-Allow-Headers", "Content-Type")
        self.end_headers()

    def do_POST(self):
        content_length = int(self.headers.get('Content-Length', 0))
        post_data = self.rfile.read(content_length)
        try: data = json.loads(post_data.decode('utf-8'))
        except json.JSONDecodeError: self._send_json_response({'success': False, 'error': 'Invalid JSON'}, status_code=400); return

        if self.path == '/download': self.handle_download_request(data)
        elif self.path == '/progress': self.handle_progress_request(data)
        elif self.path == '/info': self.handle_info_request(data)
        elif self.path == '/super-translate': self.handle_super_translate_request(data)
        elif self.path == '/super-translate-progress': self.handle_super_translate_progress(data)
        elif self.path == '/context-translate': self.handle_context_translate_request(data)
        else: self._send_json_response({'success': False, 'error': 'Endpoint not found'}, status_code=404)

    def handle_context_translate_request(self, data):
        content = data.get('content')
        # Dummy response for now
        response = {"success": True, "translated_content": content}
        self._send_json_response(response)

    def _send_json_response(self, data, status_code=200):
        self.send_response(status_code)
        self.send_header('Content-type', 'application/json')
        self.send_header('Access-Control-Allow-Origin', '*')
        self.end_headers()
        self.wfile.write(json.dumps(data).encode('utf-8'))

    def handle_download_request(self, data):
        url = data.get('url')
        if not url: self._send_json_response({'success': False, 'error': 'URL is required'}, status_code=400); return
        download_id = str(int(time.time() * 1000))
        self.download_tasks[download_id] = {'status': 'starting', 'progress': 0}
        thread = threading.Thread(target=self._execute_download, args=(download_id, data))
        thread.daemon = True; thread.start()
        self._send_json_response({'success': True, 'download_id': download_id})

    def handle_progress_request(self, data):
        download_id = data.get('download_id')
        progress_info = self.download_tasks.get(download_id, {'status': 'not_found'})
        self._send_json_response(progress_info)

    def handle_info_request(self, data):
        url = data.get('url')
        if not url: self._send_json_response({'success': False, 'error': 'URL is required'}, status_code=400); return
        try:
            cmd = ['yt-dlp', '--dump-json', '--no-playlist', url]
            result = subprocess.run(cmd, capture_output=True, text=True, check=True, encoding='utf-8')
            info = json.loads(result.stdout)
            response_data = {'title': info.get('title', 'N/A'), 'uploader': info.get('uploader', 'N/A'), 'duration': info.get('duration', 0), 'view_count': info.get('view_count', 0)}
            self._send_json_response({'success': True, 'data': response_data})
        except Exception as e: self._send_json_response({'success': False, 'error': str(e)}, status_code=500)

    def _execute_download(self, download_id, data):
        url = data.get('url'); quality = data.get('quality', 'best'); save_path = data.get('save_path', DEFAULT_DOWNLOAD_PATH); options = data.get('options', {})
        os.makedirs(save_path, exist_ok=True)
        try:
            cmd = ['yt-dlp', '-P', save_path, '--merge-output-format', 'mp4', '--progress']
            if quality == 'audio': cmd.extend(['-x', '--audio-format', 'mp3'])
            elif quality != 'best': cmd.extend(['-f', f"bv[height<=?{quality.replace('p', '')}][vcodec^=avc1]+ba/b[height<=?{quality.replace('p', '')}]/best"])
            if options.get('subtitles'): cmd.extend(['--write-subs', '--all-subs'])
            if options.get('thumbnail'): cmd.append('--write-thumbnail')
            if options.get('metadata'): cmd.append('--add-metadata')
            if options.get('playlist'): cmd.append('--yes-playlist')
            else: cmd.append('--no-playlist')
            cmd.append(url)
            self.download_tasks[download_id].update({'status': 'downloading'})
            process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, encoding='utf-8', bufsize=1)
            full_output = []
            for line in iter(process.stdout.readline, ''):
                clean_line = line.strip()
                full_output.append(clean_line)
                self._parse_progress(clean_line, download_id)
            process.stdout.close()
            if process.wait() == 0: self.download_tasks[download_id].update({'status': 'finished', 'progress': 100})
            else: 
                error_line = next((l for l in reversed(full_output) if 'error' in l.lower()), "Process failed")
                raise RuntimeError(error_line)
        except Exception as e: self.download_tasks[download_id].update({'status': 'error', 'error': str(e)})

    def _parse_progress(self, line, download_id):
        task = self.download_tasks.get(download_id)
        if not task: return
        if '[download]' in line and '%' in line:
            match = re.search(r'(\d+\.\d+)% of\s+(?:~)?([\d.]+[KMGTP]iB)\s+at\s+(.*?)\s+ETA\s+(.*)', line)
            if match: task.update({'progress': float(match.group(1)), 'size': match.group(2).strip(), 'speed': match.group(3).strip(), 'eta': match.group(4).strip()})
        elif 'Destination:' in line: task['filename'] = os.path.basename(line.split('Destination:')[-1].strip())
        elif 'Merging formats into' in line: task['status'] = 'processing'

    def handle_super_translate_request(self, data):
        content = data.get('content')
        is_json = data.get('is_json', False)
        
        if not content: self._send_json_response({'success': False, 'error': 'Content is required'}, status_code=400); return
        
        cleaned_keys = [key for key in API_KEYS if "YOUR_API_KEY" not in key]
        if not cleaned_keys: self._send_json_response({'success': False, 'error': 'Ch∆∞a ƒëi·ªÅn API Key trong file server.py'}, status_code=500); return

        try:
            if is_json:
                srt_text = parse_capcut_json_to_srt(content)
            else:
                srt_text = content
        except Exception as e:
            self._send_json_response({'success': False, 'error': f"L·ªói x·ª≠ l√Ω file: {e}"}, status_code=400)
            return

        task_id = str(int(time.time() * 1000))
        self.translation_tasks[task_id] = {'status': 'starting', 'progress': 0, 'status_text': 'B·∫Øt ƒë·∫ßu...'}
        
        thread = threading.Thread(target=self._execute_super_translation, args=(task_id, srt_text, cleaned_keys))
        thread.daemon = True; thread.start()
        self._send_json_response({'success': True, 'task_id': task_id})

    def handle_super_translate_progress(self, data):
        task_id = data.get('task_id')
        progress_info = self.translation_tasks.get(task_id, {'status': 'not_found'})
        self._send_json_response(progress_info)

    def _execute_super_translation(self, task_id, srt_text, api_keys):
        try:
            subtitles = parse_srt(srt_text)
            if not subtitles: raise ValueError("Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c file SRT. ƒê·ªãnh d·∫°ng c√≥ th·ªÉ b·ªã l·ªói.")
            task_queue = queue.Queue()
            BATCH_SIZE = 15
            total_batches = ceil(len(subtitles) / BATCH_SIZE)
            for i in range(total_batches):
                task_queue.put((i + 1, subtitles[i * BATCH_SIZE:(i + 1) * BATCH_SIZE]))
            results_dict = {}; lock = threading.Lock(); threads = []
            num_threads = len(api_keys)
            progress_tracker = ProgressTracker(len(subtitles), self.translation_tasks, task_id)
            self.translation_tasks[task_id]['status_text'] = f"Ch·∫°y {num_threads} lu·ªìng d·ªãch..."
            for i in range(num_threads):
                thread = threading.Thread(target=translation_worker, args=(i, task_queue, results_dict, lock, progress_tracker))
                threads.append(thread); thread.start()
            for thread in threads: thread.join()
            self.translation_tasks[task_id]['status_text'] = "ƒêang gh√©p file..."
            final_srt_content = ""
            translated_subtitles = []
            for index in sorted(results_dict.keys()):
                timestamp, text = results_dict[index]
                final_srt_content += f"{index}\n{timestamp.replace('.', ',')}\n{text.strip()}\n\n"
                translated_subtitles.append((index, timestamp, text))
            self.translation_tasks[task_id]['status_text'] = "ƒêang t·∫°o caption..."
            content_summary = get_content_summary(translated_subtitles)
            raw_caption_text, thumbnail_text = generate_caption_and_thumbnail(content_summary)
            prefix = "(Full Version) "; suffix = " - M·∫Øm rieview"
            branded_captions_list = []
            for block in raw_caption_text.split('==='):
                if not block.strip(): continue
                lines = block.strip().split('\n')
                title = "=== " + lines[0]
                content = lines[1] if len(lines) > 1 else ""
                hashtags = '\n'.join(lines[2:]) if len(lines) > 2 else ""
                branded_content = f"{prefix}{content}{suffix}"
                full_block = f"{title}\n{branded_content}"
                if hashtags: full_block += f"\n{hashtags}"
                branded_captions_list.append(full_block)
            final_caption_text = "\n\n".join(branded_captions_list)
            self.translation_tasks[task_id].update({
                'status': 'finished', 'progress': 100, 'status_text': 'Ho√†n th√†nh!',
                'translated_srt': final_srt_content, 'captions': final_caption_text,
                'thumbnail_text': thumbnail_text
            })
        except Exception as e:
            print(f"L·ªói khi th·ª±c thi Super Translate: {e}")
            self.translation_tasks[task_id].update({'status': 'error', 'error': str(e)})


if __name__ == '__main__':
    cleaned_keys = [key for key in API_KEYS if "YOUR_API_KEY" not in key]
    if not cleaned_keys:
        print("‚ùå M√†y ch∆∞a ƒëi·ªÅn API Key. T√¨m danh s√°ch 'API_KEYS' trong code v√† d√°n key c·ªßa m√†y v√†o.")
        sys.exit()
    print(f"‚úÖ ƒê√£ nh·∫≠n {len(cleaned_keys)} API Key. S·∫µn s√†ng chi·∫øn ƒë·∫•u.")
    try:
        os.chdir(os.path.dirname(os.path.abspath(__file__)))
        with socketserver.TCPServer(("", PORT), YouTubeDownloaderHandler) as httpd:
            print("="*50)
            print(f"üöÄ Server ƒë√£ s·∫µn s√†ng!")
            print(f"   M·ªü tr√¨nh duy·ªát v√† truy c·∫≠p: http://localhost:{PORT}")
            print(f"üìÇ T·∫£i v·ªÅ m·∫∑c ƒë·ªãnh t·∫°i: {DEFAULT_DOWNLOAD_PATH}")
            print("   Nh·∫•n Ctrl+C ƒë·ªÉ d·ª´ng server.")
            print("="*50)
            httpd.serve_forever()
    except OSError as e:
        print(f"üí• L·ªñI: Kh√¥ng th·ªÉ kh·ªüi ƒë·ªông server ·ªü c·ªïng {PORT}. C·ªïng n√†y ƒëang ƒë∆∞·ª£c d√πng?")
        print(f"   Chi ti·∫øt: {e}")
    except KeyboardInterrupt:
        print("\nüëã Server ƒë√£ d·ª´ng. T·∫°m bi·ªát!")
